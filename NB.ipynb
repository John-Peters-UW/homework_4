{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.special import softmax\n",
    "\n",
    "class NBClassifier:\n",
    "    def __init__(self) -> None:\n",
    "        self.vocab = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "                'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']\n",
    "\n",
    "        self.vectorizer = CountVectorizer(analyzer='char', vocabulary=self.vocab)\n",
    "        \n",
    "        self.training_data = None\n",
    "        self.priors = {}\n",
    "        self.model = self.get_training_data()\n",
    "        self.summerize_cols()\n",
    "        self.calculate_priors()\n",
    "\n",
    "    def calculate_priors(self):\n",
    "        predictions = []\n",
    "        num_training_samples = 0\n",
    "        for key, value in self.training_data.items():\n",
    "            num_training_samples += len(value)\n",
    "\n",
    "        for key, value in self.training_data.items():\n",
    "            self.priors[key] = (len(value) * 1.0)/num_training_samples\n",
    "\n",
    "    def get_training_data(self):\n",
    "        training_data = {}\n",
    "\n",
    "        files = os.listdir('./languageID')\n",
    "        for file in files:\n",
    "            file_name = file.split('.')[0]\n",
    "            number = int(file_name[1:])\n",
    "\n",
    "            if number >= 10:\n",
    "                continue\n",
    "\n",
    "            f = open(f\"./languageID/{file}\", 'r')\n",
    "            if file[0] in training_data:\n",
    "                training_data[file[0]].append(f.read())\n",
    "            else:\n",
    "                training_data[file[0]] = [f.read()]\n",
    "            f.close()\n",
    "\n",
    "        self.training_data = training_data\n",
    "\n",
    "        training_vectorized = {}\n",
    "        for key, value in training_data.items():\n",
    "            X = self.vectorizer.fit_transform(value)\n",
    "            training_vectorized[key] = {\n",
    "                'data': X.A\n",
    "            }\n",
    "\n",
    "        return training_vectorized\n",
    "\n",
    "    def count_total_words(self):\n",
    "        total_words = {}\n",
    "        for key, value in self.model.items():\n",
    "            data = value['data']\n",
    "            language_words = 0\n",
    "            for col_idx in range(data.shape[1]):\n",
    "                col = data[:, col_idx]\n",
    "                language_words += col.sum()\n",
    "            total_words[key] = language_words\n",
    "        \n",
    "        return total_words\n",
    "\n",
    "    def summerize_cols(self):\n",
    "        total_words = self.count_total_words()\n",
    "\n",
    "        for key, value in self.model.items():\n",
    "            stats = [] \n",
    "            data = value['data']\n",
    "            for col_idx in range(data.shape[1]):\n",
    "                col = data[:, col_idx]\n",
    "                stats.append((col.sum()/total_words[key], np.sum(col > 0)))\n",
    "            \n",
    "            self.model[key]['stats'] = stats\n",
    "        \n",
    "    def predict(self, query):\n",
    "        likelihoods = []\n",
    "        query_vector = self.vectorizer.fit_transform([query]).A.tolist()[0]\n",
    "        class_probs = []\n",
    "        \n",
    "        for key, pred_class in self.model.items():\n",
    "            class_prob = math.log(self.priors[key]) \n",
    "            # class_prob = 1\n",
    "            stats = pred_class['stats']\n",
    "            for index, (train_char_prob, count) in enumerate(stats):\n",
    "                # print(query_vector[index])\n",
    "                total_counts = sum([stat[0] for stat in stats])\n",
    "                try:\n",
    "                    char_prob = query_vector[index] * math.log(train_char_prob)\n",
    "                except:\n",
    "                    alpha = 1/2\n",
    "                    char_prob = math.log((count + alpha)/(total_counts + (3 * alpha)))      \n",
    "                \n",
    "                class_prob += char_prob\n",
    "            \n",
    "            class_probs.append(class_prob)\n",
    "            likelihoods.append((key, class_prob))\n",
    "\n",
    "        # sum_class_probs = sum(class_probs)\n",
    "        # class_probs = softmax(class_probs)\n",
    "        # for index, (key, prob) in enumerate(likelihoods):\n",
    "        #     # likelihoods[index] = (key, class_probs[index])\n",
    "        #     likelihoods[index] = (key, prob)\n",
    "            \n",
    "        return sorted(likelihoods, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e', -4687.356951143071),\n",
       " ('s', -5062.590670182352),\n",
       " ('j', -5177.933296877222)]"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(open('./languageID/e14.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14927.880918202645\n"
     ]
    }
   ],
   "source": [
    "preds = nb.predict(open('./languageID/e14.txt').read())\n",
    "total = 0\n",
    "for lang, val in preds:\n",
    "    total += val\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s', -5518.4039701552565)"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(nb.predict(open('./languageID/s12.txt').read()), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "files = os.listdir('./languageID')\n",
    "for file in files:\n",
    "    file_name = file.split('.')[0]\n",
    "    number = int(file_name[1:])\n",
    "\n",
    "    if number < 10:\n",
    "        continue\n",
    "\n",
    "    f = open(f\"./languageID/{file}\", 'r')\n",
    "    pred = max(nb.predict(f.read()), key=lambda x: x[1])[0]\n",
    "    if pred == file_name[0]:\n",
    "        preds.append(1)\n",
    "    else:\n",
    "        preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = sum(preds)/len(preds)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30\n"
     ]
    }
   ],
   "source": [
    "print(sum(preds), len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
